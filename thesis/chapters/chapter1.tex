\chapter{Introduction}
\label{chapter:introduction}

The day is September 27, 1908. The first Ford Model T has left the factory and with him the history of the automobile and transportation was forever changed~\cite{Ford, JohnSteeleGordon2007}. The Model T was not the first automobile, neither the first powered wheeled vehicle, but was the first mass-produced car in an assembly line~\cite{JohnSteeleGordon2007, DailyNews2013}. Other vehicles have preceded it, from steam carriages and coaches on the Victorian Era of Steam and electrical cars in 1888~\cite{PaulA.Hughes}, to internal combustion engines with hydrogen, kerosene and crude~\cite{Setright2003}; but none was so influential, memorable and widely adopted. 

The model T and other automobiles at an affordable price proliferated, allowing the middle-wage class to own motorized vehicles~\cite{JohnSteeleGordon2007, DailyNews2013}. The massification of such vehicles, while improving mobility of the middle class on a society at the brink of modern industrialization, started what is now one of the leading causes of mortality in the world: road accidents~\cite{WHO2018}. On the United States of America, such events triggered the foundation of the Automobile Safety League of America in 1930, which enforced the usage of seatbelts and padded dashboards. However, several decades would have to unfold before road safety became a major concern for governments, automobile manufactures, urban planners and \ac{ngo}. 

Despite all the efforts and technological advances, the number off annual global road traffic deaths is rising and it reached 1.35 million in 2018, being the leading cause of death for people aged 5 to 29 years~\cite{WHO2018}. That means that every 23 seconds a road user will die from an accident% (or 5 people since you started reading this introduction)
~\cite{WHOvisualizer}. Actions from multidisciplinary partners are being taken to reduce this growing number, such as road safety awareness campaigns, heavier fines, stricter regulations on road ans automobile safety, inspection operations and driver assistance systems~\cite{WHO2018, EUroads}. However, only 40 countries in the world have legislated on road safety and vehicle manufacturing that follows the 7 most important directives on road safety issued by \acf{who}~\cite{WHOvisualizer}. The list of countries with non-conforming legislation includes not only ``developed'' countries from Europe and the United States of America, but also ``sub-developed'' countries in Asia and Africa.

Backed both by common sense and research, human error is still the leading cause of accidents and injuries on the road~\cite{Bimbraw2015, WHO2018}, causing up to 90\% of the road accidents~\cite{WHO2018}. Distractions, fatigue, bad decisions and reckless behavior are some main reasons for human error. To reduce this grim number, manufacturers and tech companies put their efforts on developing driving systems that can aid drivers making decisions or even systems that make decisions on their own, such as adaptive headlamps and collision avoidance systems, respectively.


\begin{figure}[H]
	\centering
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/1_35-million.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_1}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/1st-cause.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_2}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/54-percent-deaths.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_3}
	\end{subfigure}
	\medskip
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/8th-leading-cause.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_4}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/Low-income-countries.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_5}
	\end{subfigure}
	\caption{Social media visuals produced by the \acf{who} for raising awareness on road safety. The data is available on the Global status report on road safety 2018~\cite{WHO2018} and the graphics material source can be found on \ac{who} website~\cite{WHOsite}.}
	\label{fig:test_image}
\end{figure}

Since the appearance of \ac{adas}, consumers, experts and governments hoped that ``smarter'' cars would result in safer roads. Several studies have been conducted on autonomous driving technology and \ac{adas}~\cite{Fridman2017, ADAS1, Bimbraw2015}, which appears as one of the most promising solutions to mitigate road accidents. Research shows that solving or at least reducing the impact of this problem could be ``easy'': remove the human driver from the driving process and replace it with autonomous driving technology. However, the problem of making autonomous driving vehicles is rather complex and has gathered the attention of both technical and non-technical personal. Newspaper articles, blog posts, podcasts and interviews have been published over the last years, revealing the interest on the topic. \ac{ai}, computer vision and autonomous driving startups have boomed in the last years and tech giants have revealed their plans to conquer this marked segment.

The automobile industry intended to improve the way humans move from a place to another, allowing faster, cheaper and more convenient transportation~\cite{Setright2003, DailyNews2013}. % By reshaping society and cities these goals have been attained, yet, some downsides are not solved, such as road safety.
While those objectives have been attained, reshaping society and cities in the process, some of their downsides are yet to be solvable, such as road safety.


\section{Scope and Motivation}
\label{sec:introduction:scope_motivation}
To build an autonomous driving vehicle as the solution to improve road safety, one needs to be capable of perceiving the world surrounding it, both accurately and in real time. The quality
of the data gathered is as crucial as its diversity, which is addressed with the usage of multiple sensors. A multiple sensor approach to autonomous driving allows:

\begin{itemize}
	\item \textbf{Data diversity:} different aspects of the surrounding environment are measured, providing complementary data;
	\item \textbf{Data redundancy:} multiple sensors complement the data gathered by each other, due to measuring the same physical phenomena with overlapping \ac{fov};
	\item \textbf{Data robustness:} since multiple sensors gather information about the vehicle surroundings in different formats, individual sensor weakness and limitations are circumvented, creating a more realistic and accurate model, even in scenarios when one sensor cannot operate properly or reliability is bad.
\end{itemize}

Autonomous driving vehicles are equipped with a wide range of sensors and systems, from parking sensors, crash detection, traffic signal detection, adaptive headlights, \ac{abs}, adaptive cruise control, among others. Regarding the perception of the environment surrounding the car, the most used sensors are:

\begin{itemize}
	\item \textbf{\ac{radar}:} capable of long range object detection, \acp{radar} uses radio waves to detect obstacles distance and velocity. It has a good performance on adverse weather conditions but lacks granularity to enable the distinction between different objects (cars, trucks, persons, etc.)
	\item \textbf{Camera:} Most accurate sensor to represent the objects of world, given good visibility conditions. Enables a good semantic view of the world, allowing the car to differentiate objects and understand their actions.  
	\item \textbf{\ac{lidar}:} medium range laser sensor that provides an accurate tridimensional view of the world.
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{img/sensor_fusion/homer_setup.png}
	\label{fig:introduction:homer_setup}
	\caption{Example of a self-driving taxi (Homer) multiple sensor setup and their relative positioning. Image source: Voyager~\cite{Cameron}.}
\end{figure}

Since \ac{darpa} Grand Challenge on the Mojave Desert, in 2004 and 2007, modern automotive \ac{lidar} has become one of the leading technologies for autonomous driving cars~\cite{Bezemek2017}. Velodyne reinvented the sensor that is now considered by many automotive companies, tech enthusiasts and experts as the crucial sensor for the fully autonomous driving cars level 5 automation, due to its precision when creating a tridimensional  model of the surrounding environment. Despite \ac{lidar} technology providing data about the environment that is not attainable with other methods, there is no consensus on the necessity of using \ac{lidar} for autonomous driving. For instance, while some authors believe \ac{lidar} to be indispensable~\cite{Bimbraw2015, Hecht2018, Sullivan2016}, Tesla is building an autonomous driving solution without \acp{lidar}, relying solely on \ac{radar} and cameras (for more information see~\cite{Bimbraw2015, Hecht2018}).


\ac{lidar} sensors map their surroundings because of their capability of precisely measuring depth, with a few centimeters of error, over distances that can range until 100 meters~\cite{vlp16, Sullivan2016} or even 300 m in certain conditions. This sensor is being employed as the solution to help cars understand the world around them, but there is a caveat that has not being addressed or deeply considered by the scientific community: \acp{lidar} interfere with their surrounding environment.

Since \ac{lidar} is an active sensor, it sends laser pulses (from a tenths to a few thousand of pulses per second) to the space surrounding them. Laser's divergence and the detector's \ac{fov} are small, but what happens when a hundred or thousands cars with \acp{lidar} ``flood'' the streets? Do they interfere mutually, i.e., the laser emitted by a \ac{lidar} on a car ``A'' interferes with the detector of the \ac{lidar} of a car ``B''? And if so, how do they interfere and are the consequences? 

In a society where the scientific community and automotive manufacturers are concerned about deploying autonomous driving technologies and cars to the streets as soon as possible, and governments lack scientific expertise to legislate on the topic, this research work focuses on understanding what happens if multiple \acp{lidar} interact with each other.

Before autonomous driving cars can replace the human driver and therefore reduce the growing
tendency for road accidents and deaths, we need to understand if the sensors we are using for the vehicles to perceive their surroundings with better accuracy than us are scalable to a scenario when the majority (or even totality) of cars are autonomous. Failing to do so, will not only delay the exciting advent of autonomous driving technology, but also fail to tackle the ever-growing problem that started such endeavour in the first place: reducing the amount of deaths on the road.

This Master's thesis intend to cast a light on this topic and provide new information about multiple \ac{lidar} interference by simply providing an answer to the question: \textit{What happens if two \acp{lidar} that coexist in the same space are switched on?} 


\section{Objectives}
\label{sec:introduction:objectives}
This Master's thesis main objective is to study the behaviour and impact of interference between \acp{lidar}. This study also aims to describe the impact of the interference in objects of interest on the \ac{lidar} \acl{fov}, performing object detection on image and computing their expected placement in a tridimensional model gathered by the \ac{lidar}.

To do this, and before making any conclusions on \ac{lidar} interference, we must attain several intermediate objectives:
\begin{enumerate}
	\item Implement an algorithm for performing extrinsic calibration between the camera and the \ac{lidar} of the experimental setup;
	\item Merge the information obtained with the camera and the \ac{lidar} to construct a more realistic scenario of the environment;
	\item Devise a series of multiples experimental setups with different metrics being varied and create a data set for future test on \ac{lidar} interference;
	\item Detect objects of interest on images and estimate their position on the	\ac{lidar} point cloud;
\end{enumerate}


\section{Document Structure} \label{sec:introduction:structure}
This document is divided in 7 chapters, including this introductory chapter:

\begin{enumerate}[label={\textbf{Chapter \arabic* -}}, align=left, itemindent=\leftmargini]
	\item \textit{\nameref{chapter:introduction}}: contextualization of the topic and scope of this document, the motivation for this research and what it attempts to solve. Briefly describes how the document is organized and the contributions associated with this research;
	\item \textit{\nameref{chapter:sota}}: \ac{lidar} technology and the available research on \ac{lidar} interference are stated on this chapter as the foundation for this research. Since camera and image object detection are also used, an overlook of camera principles, object detection on image, camera and \ac{lidar} calibration and sensor fusion is also presented. On this chapter an overview of online datasets available for this research are also presented;
	\item \textit{\nameref{chapter:calibration}}: multi sensor approach to \ac{lidar} interference requires not only a good intrinsic calibration of each sensor, but also a good calibration between the two. This chapter explains how the camera and \ac{lidar} are calibrated: both intrinsically and between them;
	\item \textit{\nameref{chapter:sensor_fusion}}: merging the information between multiple sources (sensors) generates more realistic world models. This chapter describes how calibrated online datasets and experimental data obtained can be used to color \ac{lidar} depth data;
	\item \textit{\nameref{chapter:object_detection}}: performing object detection on image allows the detection of \aclp{roi}. Using the \ac{lidar} and camera extrinsic calibration from chapter~\ref{chapter:calibration} and image detection techniques detailed on the~\ref{chapter:sota}, this chapter explains the method to create correspondences between the objects on image and their 3D counterparts on \ac{lidar};
	\item \textit{\nameref{chapter:lidar_interference}}: the study on \ac{lidar} interference is detailed on this chapter, from developing algorithms for estimating ground truth model with interference and techniques for interference analysis. The outcomes of the previous chapters are used to assess the interference on objects of interest;
	\item \textit{\nameref{chapter:conclusion}}: a summary of the results and outcomes presented and  discussed across the document and a global view of this research, along with some topics for future work.
\end{enumerate}

\section{Contributions} \label{section:introduction:contributions}
This thesis outcomes contributed to \acl{sota} of the topic with the publication of a paper entitled \textit{``Impact of Interference on Time-Of-Flight \acs{lidar}''} in the proceedings of the conference \textit{``\acl{recpad}''}, accompanied with a poster presentation on the same conference. The paper was written by Pedro Martins, António Neves, Miguel Drummond and André Albuquerque. A copy of this article is presented in \nameref{appendix:recpad}.

The \ac{lidar} and camera sensory data fusion algorithms were also presented on poster format on \textit{Students\@ DETI}, a fair on  \acl{deti} to showcase the research and projects developed by students, professors, researchers and companies.

Furthermore, during the development of the software on this thesis a contribution to the open-source package \textit{darknet\_ros}~\cite{MarkoBjelonic}, that implements a neural network for real-time detection of objects in image was made. This package is maintained by the Robotic Systems Lab of \acl{eth} and the contribution made improves the synchronization between messages, which is better detailed in chapter~\ref{chapter:object_detection}.

