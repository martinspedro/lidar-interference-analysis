\chapter{Introduction}
\label{chapter:introduction}

The day is September 27, 1908. The first Ford Model T has left the factory and with him the history of the automobile and transportation was forever changed. Model T was not the first automobile, neither the first powered wheeled vehicle, but was the first mass produced car in an assembly line. Other vehicles have preceded it, from steam carriages and coaches on the Victorian Era of Steam and  electrical cars in 1888, to internal combustion engines with hydrogen, kerosene and crude; but none was so influential, memorable and widely adopted. 

The proliferation of the model T and other automobiles at an affordable price allowed the middle-wage class to own motorized vehicles. The massification of such vehicles, while improving mobility of the middle class on a society at the brink of modern industrialization, started what is now one of the leading causes of mortality in the world: road accidents. On America, such events would lay the foundation of the Automobile Safety League of America in 1930, which enforced the usage of seatbelts and padded dashboards. However, several decades would have yet to unfold before road safety became a major concern for governments, automobile manufactures, urban planners and \ac{ngo}. 

Despite all the efforts and technological advances, annual global road traffic deaths are rising and reached 1.35 millions in 2018, being the leading cause of death for people aged 5-29 years \cite{WHO2018}. That means that every 23 seconds a road user will die from an accident (or 5 people since you started reading this introduction).  Actions from multidisciplinary partners are been taken in order to reduce this ever growing number, such as road safety awareness campaigns, better laws, heavier fines, stricter regulations on automobile safety, inspection operations and driver assistance systems. However, only 40 countries in the world have legislate on road safety and vehicle manufacturing that follows the 7 most important directives on road safety issued by \ac{WHO}. The list of countries with non-conforming legislation includes not only ``developed'' countries from Europe and the United States of America, but also ``sub-developed'' countries in the Asia and African continents.

Backed both by common sense and research, human error is still the leading cause of accidents and injuries on the road \cite{Bimbraw2015, WHO2018}, causing up to 90\% of the road accidents. Distractions, fatigue, bad decisions and reckless behavior are some of the main reasons for human error. To reduce this grim number, manufacturers and tech companies put their efforts on developing driving systems that can aid the driver making decisions or even systems that make decisions on their own, such as adaptive headlamps and collision avoidance systems, respectively.

Since the appearance of \ac{adas}, consumers, experts and governments hoped that ``smarter'' cars would result in safer roads. Several studies have been conducted on autonomous driving technology and \ac{adas} \cite{Fridman2017, ADAS1, Bimbraw2015}, which appears as one of the most promising solutions to mitigate road accidents. Solving (or at least reducing the impact of) this problem is, therefore, ``easy'': remove the human driver from the driving process and replace it with autonomous driving technology. However, the problem of making autonomous driving vehicles  is rather complex and have gathered the attention of both technical and non-technical personal. Newspaper articles, blog posts, podcasts and interviews have been published over the last years, revealing the interest on the topic. \ac{AI}, computer vision and autonomous driving startups have boomed in the last years and tech giants have revealed their plans to conquer this marked segment.

The automobile intended to improve the way humans move from a place to another, allowing faster, cheaper and more convenient transportation. While those objectives have been attained, reshaping society and cities in the process, some of their downsides are yet to be solvable, such as road safety.


\section{Scope and Motivation}
\label{sec:introduction:scope_motivation}
Building an autonomous driving vehicle as the solution to improve road safety requires the vehicle to be capable of perceiving the world surrounding it, both accurately and in real time. The quality of the data gathered is as crucial as it diversity, addressed with the usage of multiple sensors. A multiple sensor approach to autonomous driving allows:

\begin{itemize}
	\item \textbf{Data diversity:} different aspects of the surrounding environment are measured, providing complementary data;
	\item \textbf{Data redundancy:} multiple sensors that measure the same physical phenomena's with overlapping \ac{fov} complement the data gather by other(s) sensor(s);
	\item \textbf{Data robustness:} since multiple sensors gather information about the vehicle surroundings in different formats, individual sensor weakness and limitations are circumvented, creating a more realistic and accurate model, even in scenarios when one sensor cannot operate properly or reliability is bad.
\end{itemize}

Autonomous driving vehicles are equipped with a wide range of sensors and systems, from parking sensors, crash detection, traffic signal detection, adaptive headlights, \ac{ABS}, adaptive cruise control, among so many others. Regarding the perception of the environment surrounding the car, the most common sensors that are used are:

\begin{itemize}
	\item \textbf{\ac{radar}:} capable of long range object detection, \acp{radar} uses radio waves to detect obstacles distance and velocity. Has a good performance on adverse meteorologic conditions but lacks granularity to enable the distinction between different objects (cars, trucks, persons, etc.)
	\item \textbf{Camera:} Most accurate sensor to represent the objects of world, given good visibility conditions. Enables a very good semantic view of the world, allowing the car to differentiate objects and understand their actions. Requires good visibility conditions 
	\item \textbf{\ac{lidar}:} medium range laser sensor that provides an accurate tridimensional view of the world.
\end{itemize}


Since \ac{darpa} Grand Challenge on the Mojave Desert, in 2004 and 2007, modern automotive \ac{lidar} has become one of the leading technologies for autonomous driving cars. Velodyne reinvented the sensor that is now considered by many companies ...  (with some exceptions, see ...) the most important sensor on autonomous driving, due to its precision when creating a tridimensional  model of the surrounding environment.


\ac{lidar} sensors map their surroundings thanks to their capability of precisely measuring depth - with a few centimeters of error, over distances that can range until 100 meters \cite{vlp16, Sullivan2016} or even 300 m in certain conditions. This sensor is being employed as the solution to help cars understand the world around them, but there is a caveat that was not yet being addressed or deeply considered by the scientific community: \acp{lidar} interfere with their surrounding environment.

Since \ac{lidar} is an active sensor, it sends from tenths of laser pulses per second to a few thousand to the space surrounding them. The divergence of the laser and the field of view of the detector are small, but what happens when hundred or thousands of cars with \acp{lidar} ``flood'' the streets. Do they interfere mutually, i.e., the laser emitted by a \ac{lidar} on a car ``A'' interferes with the detector of the \ac{lidar} of a car ``B''? If so, what happens? 

In a society when the scientific community and automotive manufacturers are concerned about deploying autonomous driving technologies and cars to the streets as soon as possible and governments lack scientific expertise to legislate on the topic, this research work focus on understanding what happens if multiple \acp{lidar} interact.

Before autonomous driving cars can replace the human driver and therefore reduce the growing tendency for road accidents and deaths, it is require to understand if the sensors we are using for the vehicles to perceive their surroundings with better accuracy than us are scalable to a scenario when the majority (or even totality) of cars are autonomous. Failing to do so, will not only delay the exciting advent of autonomous driving technology, but also fail to tackle the ever growing problem that started such endeavour in the first place: reducing the amount of deaths on the road.

This Master's thesis intend to cast a light on this topic and provide new information about multiple \ac{lidar} interference by simply providing an answer to the question: \textit{What happens if two \acp{lidar} that coexist in the same space are switched on?} 

% \ac{tof} \ac{lidar}, the most common type, acquires depth information by measuring the time elapsed between the emission and reception of a laser pulse reflected from a surrounding target \cite{Sullivan2016}. 




%To scan a single line, a single pair of laser and photodetector are assembled on a rotational device, creating a 2D \ac{lidar}. If multiple pairs are assembled together, on a rotational device, with different polar angles, the \ac{lidar} is said to be a 3D \ac{lidar}.

%These maps, commonly represented as point clouds or mesh clouds, are one of the preferred method for \ac{slam} algorithms, which allows a vehicle without previous knowledge of its surroundings to autonomously navigate them - a crucial task for \ac{adas} on self-driving vehicles.

%Normally, this pair of laser and photodetector is assembled on a rotational device, allowing a single pair to measure a line, creating a 2D \ac{lidar}. If multiple pairs are assembled together, with different polar angles, the \ac{lidar} is said to be 3D, since a total revolution can produce a three dimensional map of its surroundings. 



%Along with some public datasets that have been made available to enable progress of self-driving vehicles \cite{Geiger2012}, \ac{adas} is becoming more relevant, mainly due to the maturation of \ac{lidar} technology \cite{Sullivan2016}. 


\section{Objectives}
\label{sec:introduction:objectives}
This Master's thesis main objective is to study the behaviour and impact of interference between \acp{lidar}. This study also aims to describe the impact of the interference in objects of interest on the \ac{lidar} \acl{fov}, performing object detection on image and computing their expected placement in a tridimensional model gather by the \ac{lidar}.

For that, before any conclusions can be made on \ac{lidar} interference, several intermediate objectives must been attainable before:
\begin{enumerate}
	\item Implement an algorithm for performing extrinsic calibration between the camera and the \ac{lidar} of the experimental setup;
	\item Merge the information obtained with the camera and the \ac{lidar} to construct a more realistic scenario of the environment;
	\item Devise a series of multiples experimental setups with different metrics being varied and create a data set for future test on \ac{lidar} interference;
	\item Detect objects of interest on images and estimate their position on the	\ac{lidar} point cloud;
\end{enumerate}


\section{Document Structure} \label{sec:introduction:structure}
This document is divided in 7 chapters, including this introductory chapter:

\begin{enumerate}[label={\textbf{Chapter \arabic* -}}, align=left, itemindent=\leftmargini]
	\item \textit{\nameref{chapter:introduction}}: contextualization of the topic and scope of this document, the motivation for this research and what it attempts to solve. Briefly describes how the document is organized and the contributions associated with this research;
	\item \textit{\nameref{chapter:sota}}: \ac{lidar} technology and the available research on \ac{lidar} interference are stated on this chapter as the foundation for this research. Since camera and image object detection are also used, an overlook of camera principles, object detection on image and camera an \ac{lidar} calibration and sensor fusion are also presented. On this chapter an overview of online datasets available for this research are also presented.
	\item \textit{\nameref{chapter:calibration}}: multi sensor approach to the thematic of \ac{lidar} interference require no only a good intrinsic calibration of each sensor, but also a good calibration between the two. On this chapter is given an explanation on how the camera and \ac{lidar} are calibrated on their own and together
	\item \textit{\nameref{chapter:sensor_fusion}}: merging the information between multiple sources (sensors) allows the generation of more realistic world models. This chapter describes how calibrated online datasets and experimental data obtained can be used to color \ac{lidar} depth data;
	\item \textit{\nameref{chapter:object_detection}}: performing object detection on image allows the detection of \acp{roi} on image. Using the \ac{lidar} and camera extrinsic calibration  of chapter \ref{chapter:calibration} and image detection techniques detailed on the \nameref{chapter:sota}, this chapter explains the method to create correspondences between the objects on image and their 3D counterparts on \ac{lidar};
	\item \textit{\nameref{chapter:lidar_interference}}: the study on \ac{lidar} interference is detailed on this chapter, from developing algorithms for estimating ground truth model with interference and techniques for interference analysis. The outcomes of the previous chapters are used to asses the interference on particular objects of interest;
	\item \textit{\nameref{chapter:conclusion}}: the results and outcomes presented and presented and  discussed across the document are summarized and a global view of this research is given, along with some topics for future work.
\end{enumerate}

\section{Contributions} \label{section:introduction:contributions}
This thesis outcomes contributed to \acl{sota} of the topic with the publication of an article entitled \textit{``Impact of Interference on Time-Of-Flight \acs{lidar}''} in the proceedings of the conference \textit{``\acl{recpad}''}, accompanied with a poster presentation on the same conference. The article was written by Pedro Martins, António Neves, Miguel Drummond and André Albuquerque. A copy of this article is presented in \nameref{appendix:recpad}.

The \ac{lidar} and camera sensory data fusion algorithms were also presented on poster format on \textit{Students\@ DETI}, a fair on  \acl{deti} to showcase the research and projects develop by students, professors, researchers and companies.

Furthermore, during the development of the software on this thesis a contribution to the open-source package \textit{darknet\_ros}, that implements a neural network for real-time detection of objects in image was made, improving the synchronization between messages. This contribution is better detailed in chapter \ref{chapter:object_detection}.

% However, despite being a complex and broad research area, most of the current state-of-the-art for autonomous driving relies heavily on \ac{lidar} - a device capable of measuring the depth from a scene by using laser beams. 

\subsection{\ac{lidar} Interference}
\ac{tof} \ac{lidar}s basic principle implies that when a laser pulse is emitted, three different scenarios are possible, being the first one the only one that produces a valid measurement:
\begin{enumerate}
    \itemsep0em
    \item The laser pulse returns, due to the reflection of an obstacle;
    \item The laser pulse does not return;
    \item The laser pulse returns with intensity below the noise floor.
\end{enumerate}

Interference and crosstalk between the pairs of lasers and photodetectors on a \ac{lidar} are mitigated with different firing offsets, or in the case of mutual interference between \ac{lidar}, it is possible to synchronize their firing time using specialized clock signals \cite{vlp16}.

However, in a society when self-driving vehicles coexist, another scenario is possible: a \ac{lidar} ``A'' fires a laser pulse that is received, directly or indirectly, by the photodetector on a \ac{lidar} ``B''. Since \ac{lidar} ``B'' measures the distance to an obstacle by measuring the time between the firing and reception of its own laser pulse, the reception of another laser pulse results in an erroneous measure with an unpredictable behavior. If this interference is significant, the reliability of the \ac{lidar}, and consequently autonomous vehicles and \ac{adas}, is seriously undermined due to the incapability to accurately mapping their surroundings.

To the best of the author's knowledge, despite the relevance of the topic to a society of self-driving cars, there are only available the studies conducted by Kim \etal \cite{Kim2017, Kim2015}, which seek to characterize this interference; and by Retterath and Laumeyer \cite{Al.2013}, seeking to provide an apparatus for reducing the mutual interference of \ac{lidar} sensors on the same vehicle.

%Despite the relevance of the topic for the massification of self-driving vehicles and the hazardous impact on \ac{adas} reliability, the research topic presented in this paper has received very reduced attention by the research community. 
%A major \ac{lidar} manufacture also addresses the problem of mutual interference of the \ac{lidar} sensors on the same vehicle, by allowing their synchronization and laser firing in different instants \cite{vlp16}.

Kim \etal research %despite using a 2D \ac{lidar}%instead of a 3D \ac{lidar}
is the only study to use two independent 2D \ac{lidar}s interfering with each other. Kim \etal results indicate that interference has spatial and temporal locality \cite{Kim2015} and in any given time, in Kim's setup, a data point has 0.05 \% probability of being interfered \cite{Kim2015}.
%The former states that if a particular angle is interfered, the following angles are likely to also be interfered; while the latter indicates that if a measure is interfered, on the following frame that same measure is also likely to be interfered. 
%However, 



