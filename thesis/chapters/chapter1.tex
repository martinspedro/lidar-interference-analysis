\chapter{Introduction}
\label{chapter:introduction}

The day is September 27, 1908. The first Ford Model T has left the factory and with him the history of the automobile and transportation was forever changed~\cite{Ford, JohnSteeleGordon2007}. Model T was not the first automobile, neither the first powered wheeled vehicle, but was the first mass-produced car in an assembly line~\cite{JohnSteeleGordon2007, DailyNews2013}. Other vehicles have preceded it, from steam carriages and coaches on the Victorian Era of Steam and electrical cars in 1888~\cite{PaulA.Hughes}, to internal combustion engines with hydrogen, kerosene and crude~\cite{Setright2003}; but none was so influential, memorable and widely adopted. 

The proliferation of the model T and other automobiles at an affordable price allowed the middle-wage class to own motorized vehicles~\cite{JohnSteeleGordon2007, DailyNews2013}. The massification of such vehicles, while improving mobility of the middle class on a society at the brink of modern industrialization, started what is now one of the leading causes of mortality in the world: road accidents~\cite{WHO2018}. On America, such events would lay the foundation of the Automobile Safety League of America in 1930, which enforced the usage of seatbelts and padded dashboards. However, several decades would have yet to unfold before road safety became a major concern for governments, automobile manufactures, urban planners and \ac{ngo}. 

Despite all the efforts and technological advances, annual global road traffic deaths are rising and reached 1.35 millions in 2018, being the leading cause of death for people aged 5 to 29 years~\cite{WHO2018}. That means that every 23 seconds a road user will die from an accident (or 5 people since you started reading this introduction)~\cite{WHOvisualizer}. Actions from multidisciplinary partners are been taken in order to reduce this ever growing number, such as road safety awareness campaigns, better laws, heavier fines, stricter regulations on automobile safety, inspection operations and driver assistance systems~\cite{WHO2018, EUroads}. However, only 40 countries in the world have legislated on road safety and vehicle manufacturing that follows the 7 most important directives on road safety issued by \acf{who}~\cite{WHOvisualizer}. The list of countries with non-conforming legislation includes not only ``developed'' countries from Europe and the United States of America, but also ``sub-developed'' countries in the Asia and African continents.

Backed both by common sense and research, human error is still the leading cause of accidents and injuries on the road~\cite{Bimbraw2015, WHO2018}, causing up to 90\% of the road accidents~\cite{WHO2018}. Distractions, fatigue, bad decisions and reckless behavior are some main reasons for human error. To reduce this grim number, manufacturers and tech companies put their efforts on developing driving systems that can aid the driver making decisions or even systems that make decisions on their own, such as adaptive headlamps and collision avoidance systems, respectively.


\begin{figure}[H]
	\centering
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/1_35-million.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_1}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/1st-cause.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_2}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/54-percent-deaths.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_3}
	\end{subfigure}
	\medskip
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/8th-leading-cause.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_4}
	\end{subfigure}
	\quad
	\begin{subfigure}[c]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/road_safety/Low-income-countries.jpg}
		%\caption{Picture 1}
		\label{fig:test_image_5}
	\end{subfigure}
	\caption{Social media visuals produced by the \acf{who} for raising awareness on road safety. The data is available on the Global status report on road safety 2018~\cite{WHO2018} and the graphics material source can be found on \ac{who} website~\cite{WHOsite}.}
	\label{fig:test_image}
\end{figure}

Since the appearance of \ac{adas}, consumers, experts and governments hoped that ``smarter'' cars would result in safer roads. Several studies have been conducted on autonomous driving technology and \ac{adas}~\cite{Fridman2017, ADAS1, Bimbraw2015}, which appears as one of the most promising solutions to mitigate road accidents. Solving (or at least reducing the impact of) this problem is, therefore, ``easy'': remove the human driver from the driving process and replace it with autonomous driving technology. However, the problem of making autonomous driving vehicles  is rather complex and have gathered the attention of both technical and non-technical personal. Newspaper articles, blog posts, podcasts and interviews have been published over the last years, revealing the interest on the topic. \ac{ai}, computer vision and autonomous driving startups have boomed in the last years and tech giants have revealed their plans to conquer this marked segment.

The automobile intended to improve the way humans move from a place to another, allowing faster, cheaper and more convenient transportation~\cite{Setright2003, DailyNews2013}. While those objectives have been attained, reshaping society and cities in the process, some of their downsides are yet to be solvable, such as road safety.


\section{Scope and Motivation}
\label{sec:introduction:scope_motivation}
Building an autonomous driving vehicle as the solution to improve road safety requires the vehicle
to be capable of perceiving the world surrounding it, both accurately and in real time. The quality
of the data gathered is as crucial as its diversity, addressed with the usage of multiple sensors. A multiple sensor approach to autonomous driving allows:

\begin{itemize}
	\item \textbf{Data diversity:} different aspects of the surrounding environment are measured, providing complementary data;
	\item \textbf{Data redundancy:} multiple sensors that measure the same physical phenomena's with overlapping \ac{fov} complement the data gather by other(s) sensor(s);
	\item \textbf{Data robustness:} since multiple sensors gather information about the vehicle surroundings in different formats, individual sensor weakness and limitations are circumvented, creating a more realistic and accurate model, even in scenarios when one sensor cannot operate properly or reliability is bad.
\end{itemize}

Autonomous driving vehicles are equipped with a wide range of sensors and systems, from parking sensors, crash detection, traffic signal detection, adaptive headlights, \ac{abs}, adaptive cruise control, among so many others. Regarding the perception of the environment surrounding the car, the most common sensors that are used are:

\begin{itemize}
	\item \textbf{\ac{radar}:} capable of long range object detection, \acp{radar} uses radio waves to detect obstacles distance and velocity. Has a good performance on adverse meteorologic conditions but lacks granularity to enable the distinction between different objects (cars, trucks, persons, etc.)
	\item \textbf{Camera:} Most accurate sensor to represent the objects of world, given good visibility conditions. Enables a good semantic view of the world, allowing the car to differentiate objects and understand their actions. Requires good visibility conditions 
	\item \textbf{\ac{lidar}:} medium range laser sensor that provides an accurate tridimensional view of the world.
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{img/sensor_fusion/homer_setup.png}
	\label{fig:introduction:homer_setup}
	\caption{Example of a self-driving taxi (Homer) multiple sensor setup and their relative positioning. Image source: Voyager~\cite{Cameron}.}
\end{figure}

Since \ac{darpa} Grand Challenge on the Mojave Desert, in 2004 and 2007, modern automotive \ac{lidar} has become one of the leading technologies for autonomous driving cars~\cite{Bezemek2017}. Velodyne reinvented the sensor that is now considered by many automotive companies, tech enthusiasts and experts as the crucial sensor for the fully autonomous driving cars level 5 automation, due to its precision when creating a tridimensional  model of the surrounding environment. Despite \ac{lidar} technology providing data about the environment that is not attainable with other methods, there is no consensus on the necessity of using \ac{lidar} for autonomous driving. Tesla and (name other companies) are building an autonomous driving solution without \acp{lidar} (for more information see). 


\ac{lidar} sensors map their surroundings thanks to their capability of precisely measuring depth - with a few centimeters of error, over distances that can range until 100 meters~\cite{vlp16, Sullivan2016} or even 300 m in certain conditions. This sensor is being employed as the solution to help cars understand the world around them, but there is a caveat that was not yet being addressed or deeply considered by the scientific community: \acp{lidar} interfere with their surrounding environment.

Since \ac{lidar} is an active sensor, it sends from tenths of laser pulses per second to a few thousand to the space surrounding them. The divergence of the laser and the field of view of the detector are small, but what happens when a hundred or thousands cars with \acp{lidar} ``flood'' the streets. Do they interfere mutually, i.e., the laser emitted by a \ac{lidar} on a car ``A'' interferes with the detector of the \ac{lidar} of a car ``B''? If so, what happens? 

In a society when the scientific community and automotive manufacturers are concerned about deploying autonomous driving technologies and cars to the streets as soon as possible and governments lack scientific expertise to legislate on the topic, this research work focus on understanding what happens if multiple \acp{lidar} interact.

Before autonomous driving cars can replace the human driver and therefore reduce the growing
tendency for road accidents and deaths, we need to understand if the sensors we are using for the vehicles to perceive their surroundings with better accuracy than us are scalable to a scenario when the majority (or even totality) of cars are autonomous. Failing to do so, will not only delay the exciting advent of autonomous driving technology, but also fail to tackle the ever growing problem that started such endeavour in the first place: reducing the amount of deaths on the road.

This Master's thesis intend to cast a light on this topic and provide new information about multiple \ac{lidar} interference by simply providing an answer to the question: \textit{What happens if two \acp{lidar} that coexist in the same space are switched on?} 


\section{Objectives}
\label{sec:introduction:objectives}
This Master's thesis main objective is to study the behaviour and impact of interference between \acp{lidar}. This study also aims to describe the impact of the interference in objects of interest on the \ac{lidar} \acl{fov}, performing object detection on image and computing their expected placement in a tridimensional model gather by the \ac{lidar}.

For that, before any conclusions can be made on \ac{lidar} interference, several intermediate objectives must have been attainable before:
\begin{enumerate}
	\item Implement an algorithm for performing extrinsic calibration between the camera and the \ac{lidar} of the experimental setup;
	\item Merge the information obtained with the camera and the \ac{lidar} to construct a more realistic scenario of the environment;
	\item Devise a series of multiples experimental setups with different metrics being varied and create a data set for future test on \ac{lidar} interference;
	\item Detect objects of interest on images and estimate their position on the	\ac{lidar} point cloud;
\end{enumerate}


\section{Document Structure} \label{sec:introduction:structure}
This document is divided in 7 chapters, including this introductory chapter:

\begin{enumerate}[label={\textbf{Chapter \arabic* -}}, align=left, itemindent=\leftmargini]
	\item \textit{\nameref{chapter:introduction}}: contextualization of the topic and scope of this document, the motivation for this research and what it attempts to solve. Briefly describes how the document is organized and the contributions associated with this research;
	\item \textit{\nameref{chapter:sota}}: \ac{lidar} technology and the available research on \ac{lidar} interference are stated on this chapter as the foundation for this research. Since camera and image object detection are also used, an overlook of camera principles, object detection on image and camera an \ac{lidar} calibration and sensor fusion are also presented. On this chapter an overview of online datasets available for this research are also presented.
	\item \textit{\nameref{chapter:calibration}}: multi sensor approach to the thematic of \ac{lidar} interference require no only a good intrinsic calibration of each sensor, but also a good calibration between the two. On this chapter is given an explanation on how the camera and \ac{lidar} are calibrated on their own and together
	\item \textit{\nameref{chapter:sensor_fusion}}: merging the information between multiple sources (sensors) allows the generation of more realistic world models. This chapter describes how calibrated online datasets and experimental data obtained can be used to color \ac{lidar} depth data;
	\item \textit{\nameref{chapter:object_detection}}: performing object detection on image allows the detection of \aclp{roi} on image. Using the \ac{lidar} and camera extrinsic calibration of chapter~\ref{chapter:calibration} and image detection techniques detailed on the \nameref{chapter:sota}, this chapter explains the method to create correspondences between the objects on image and their 3D counterparts on \ac{lidar};
	\item \textit{\nameref{chapter:lidar_interference}}: the study on \ac{lidar} interference is detailed on this chapter, from developing algorithms for estimating ground truth model with interference and techniques for interference analysis. The outcomes of the previous chapters are used to asses the interference on particular objects of interest;
	\item \textit{\nameref{chapter:conclusion}}: the results and outcomes presented and presented and  discussed across the document are summarized and a global view of this research is given, along with some topics for future work.
\end{enumerate}

\section{Contributions} \label{section:introduction:contributions}
This thesis outcomes contributed to \acl{sota} of the topic with the publication of an article entitled \textit{``Impact of Interference on Time-Of-Flight \acs{lidar}''} in the proceedings of the conference \textit{``\acl{recpad}''}, accompanied with a poster presentation on the same conference. The article was written by Pedro Martins, António Neves, Miguel Drummond and André Albuquerque. A copy of this article is presented in \nameref{appendix:recpad}.

The \ac{lidar} and camera sensory data fusion algorithms were also presented on poster format on \textit{Students\@ DETI}, a fair on  \acl{deti} to showcase the research and projects develop by students, professors, researchers and companies.

Furthermore, during the development of the software on this thesis a contribution to the open-source package \textit{darknet\_ros}~\cite{MarkoBjelonic}, that implements a neural network for real-time detection of objects in image was made. This package is maintained by the Robotic Systems Lab of \acl{eth} and the contribution made improves the synchronization between messages, which is better detailed in chapter~\ref{chapter:object_detection}.

