\chapter{\acl{sota}}
\label{chapter:sota}

\section{Datasets}
\label{section:sota:datasets}

Training an autonomous vehicle to be capable of driving himself is a challenge that requires huge amounts of data: both to train neural networks and to test algorithms. Collaborative effort has been made to ease the process and several data sets are available online for public usage. They vary in the sensory data available, conditions whose data has been acquired, driving conditions and format on which they are provided, among others. 

Despite this work not being focus on autonomous driving, the algorithms developed for calibration, sensor fusion and correspondence detection between image and point cloud are not meant to be particular applied on datasets with interference. Using public available datasets not only allow the development of those algorithms before experimental data can be gathered, but also ensures that they are no application specific and can be reused on public datasets.

During this research work, several new datasets have become online, such as
nuScenes~\cite{nuScenes2019} and Waymo~\cite{Waymo}. Those were not investigated nor used as a part
of this research since the datasets that were been used suffice.

For the purposes of this research, several datasets were analyzed and searched. Above are listed only the ones that made it to the final decision criteria, i.e., have \ac{lidar} and camera:

\subsection{Ford Campus \ac{lidar} dataset}
Gathered in 2009, on the Ford Research campus and downtown Dearborn, in Michigan, this dataset contains camera, \ac{lidar}, \ac{imu} and \ac{gps} data. The dataset consists of two test runs, one inside the campus and another on downtown. 

The data is provided in raw format, accompanied by log files for pose, timestamps, \ac{gps} and \ac{lcm}\footnote{For more information on \acf{lcm}, see~\cite{Wang2018a}.}. Images are stored on \ac{ppm} and \ac{lidar} data on \ac{pcap} format. The data is unrectified and unsynced, but source code to parse and analyze the data is provided, along with some calibration parameters, in C or \ac{matlab}.

For the navigation, the modified Ford F-250 pickup truck uses 3 sensors~\cite{Pandey2011}: one 3D \ac{lidar}, Velodyne HDL-64E lidar~\cite{Wang2018a}; one camera: Point Grey Ladybug3 omnidirectional camera; and two 2D \acp{lidar}: Riegl LMS-Q120 lidar.


\subsection{\ac{kitti}}
\ac{kitti} dataset is a well known dataset for researchers of computer vision and autonomous driving. Recorded in 2011 and released for the public in 2013, this dataset contains various driving scenarios, from suburban, highways, residential and campus areas. It also provides some datasets with only people and calibration data.

This dataset was acquired using a Volkswagen Passat station wagon and the data is provided in raw format, accompanied by logs containing the timestamps. The dataset contains two stereo pairs, one with color and other with gray cameras, a \ac{lidar} and \ac{imu}+\ac{gps} sensor. Camera data is stored on \ac{png} format and \ac{lidar} data as a binary float matrix. \ac{gps} and {imu} data are stored textually. Additionally, tracklets can be provided for some datasets on \ac{xml} files.

Along with the data and calibration parameters, several tools written in C++ or \ac{matlab} are also provided. The dataset offers unsynced and unrectified data but also synced and rectified data. Calibration parameters and the data used to estimate it is also provided.

The sensory apparatus contains 2 PointGray Flea2 greyscale and color cameras, a Velodyne HDL-64E lidar~\cite{Wang2018a}, among others~\cite{Geiger2013a}.






\subsection{Udacity Self-Driving Car Nanodegree Dataset:}
Udacity online course on self-driving technology shares its data and some tools to help students enroll.

Their dataset is presented on an organized format ready to be used by \ac{ros} and they also provide some tools for visualizing and interacting with their data~\cite{udacity}. Furthermore, this data contains images from 3 color cameras, a \ac{lidar},  \ac{imu} and \ac{gps}, and data from other sensors, such as speed, braking, etc.

\subsection{Summary}
Table~\ref{tab:sota:datasets_comparison} summarizes all the relevant data from the datasets~\cite{udacity, Pandey2011, Geiger2013a}. We can see that there are few differences between the relevant types of data gather but major differences can be seen on the format provided. While \ac{kitti} not only provides the largest dataset in quantity, but also provides rectified and synced data. For the purposes of this research, there is no interest in testing syncing and rectification methods, which penalizes Ford dataset. 

While Udacity dataset is the newest and provides direct out-off-the-shelf integration with \ac{ros}, that type of integration can also be achieved for \ac{kitti} by using other tools, such as \textit{kitti2bag}~\cite{TomasKrejci}. 
	
\begin{table}[H]
	 \rowcolors{4}{gray!10}{white}
	 \renewcommand{\arraystretch}{1.2}
	 \centering
	\begin{tabular}{llccc}
																& & \multicolumn{3}{c}{Datasets} \\ \cline{3-5}
																& & Ford Campus  & \acs{kitti} & Udacity \\ \midrule
																& \ac{lidar}	& \checkmark  & \checkmark & \checkmark \\ 
																& Color Camera & \checkmark   &  \checkmark  &  \checkmark  \\
																& Grey Cameras &  &  \checkmark  &  \\
																& Stereo Camera &  &  \checkmark  &  \checkmark  \\
																& Omnidirectional Camera &  \checkmark  &  &  \\
																& \acs{imu} &  \checkmark  &  \checkmark  &  \checkmark  \\
																& \acs{gps} &  \checkmark  &  \checkmark  &  \checkmark  \\
		\rowcolor{white}\multirow{-8}{*}{Data Types} 														& Other data relevant to autonomous driving & & & \checkmark \\
		\multirow{5}{*}{Formats and Tools} & Raw data available &  \checkmark  &  \checkmark  &  \\
																			 & Data parsing tools &  \checkmark  &\checkmark    &  \checkmark  \\
																			 & Rectified data & & \checkmark  & \\
																			 & Synced data &  & \checkmark   &  \checkmark  \\ 
																			 & Calibration parameters & \checkmark  & \checkmark  & \checkmark  \\
		\multicolumn{2}{l}{Raw data for calibration} & & \checkmark & \\
		\multicolumn{2}{l}{\ac{ros} data compatibility} &  &  \checkmark\footnotemark &  \checkmark  \\
		\bottomrule
	\end{tabular}
\caption{Comparison between the datasets more appropriated to this thesis objectives}
\label{tab:sota:datasets_comparison}
\end{table}
\footnotetext{Requires the usage of an external tool \textit{kitti2bag}~\cite{TomasKrejci}} 

At the time this research began, Udacity and \ac{kitti} data sets are the most appealing to be used. Prioritizing ease of use, Udacity data set trumps over \ac{kitti}, since \ac{ros} will be a tool usage on this research as well.


	
